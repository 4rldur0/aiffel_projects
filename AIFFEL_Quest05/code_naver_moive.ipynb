{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb645dd",
   "metadata": {},
   "source": [
    "[NAVER sentiment movie corpus](https://github.com/e9t/nsmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac4cae",
   "metadata": {},
   "source": [
    "- [1) 데이터 준비와 확인](#1%29-데이터-준비와-확인)\n",
    "- [2) 데이터로더 구성](#2%29-데이터로더-구성)\n",
    "- [3) 모델 구성을 위한 데이터 분석 및 가공](#3%29-모델-구성을-위한-데이터-분석-및-가공)\n",
    "- [4) 모델 구성 및 validation set 구성](#4%29-모델-구성-및-validation-set-구성)\n",
    "- [5) 모델 훈련 개시](#5%29-모델-훈련-개시)\n",
    "- [6) Loss, Accuracy 그래프 시각화](#6%29-Loss,-Accuracy-그래프-시각화)\n",
    "- [7) 학습된 Embedding 레이어 분석](#7%29-학습된-Embedding-레이어-분석)\n",
    "- [8) 한국어 Word2Vec 임베딩 활용하여 성능 개선](#8%29-한국어-Word2Vec-임베딩-활용하여-성능-개선)\n",
    "- [회고](#회고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88579924",
   "metadata": {},
   "source": [
    "# 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f448308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15026485",
   "metadata": {},
   "source": [
    "# 2) 데이터로더 구성\n",
    "- [x] 데이터의 중복 제거 -> 중복 없음.  \n",
    "- [x] NaN 결측치 제거  \n",
    "- [x] 한국어 토크나이저로 토큰화  \n",
    "- [x] 불용어(Stopwords) 제거  \n",
    "- [x] 사전 word_to_index 구성  \n",
    "- [x] 텍스트 스트링을 사전 인덱스 스트링으로 변환  \n",
    "- [x] X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19efbf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words = 10000):\n",
    "    # 중복 제거\n",
    "    # 중복 데이터 없음.\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    \n",
    "    # NaN 결측치 제거\n",
    "    # document 열에만 NA있어서 바로 제거\n",
    "    train_data = train_data.dropna(how = 'any')\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    # 토큰화, 불용어 처리\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    # 사전 word_to_index\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words - 4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "    \n",
    "    # 텍스트 to 인덱스\n",
    "    def wordlist_to_idxlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "    \n",
    "    X_train = list(map(wordlist_to_idxlist, X_train))\n",
    "    X_test = list(map(wordlist_to_idxlist, X_test))\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3f18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90393631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4c1ee",
   "metadata": {},
   "source": [
    "# 3) 모델 구성을 위한 데이터 분석 및 가공\n",
    "- [x] 데이터셋 내 문장 길이 분포\n",
    "- [x] 적절한 최대 문장 길이 지정\n",
    "- [x] keras.preprocessing.sequence.pad_sequences 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596bde53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3e2a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d510c",
   "metadata": {},
   "source": [
    "# 4) 모델 구성 및 validation set 구성\n",
    "- [x] 3가지 이상 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb4a9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29236\n",
      "(116946, 41)\n",
      "(116946,)\n"
     ]
    }
   ],
   "source": [
    "train_len = int(X_train.shape[0] * 0.2)\n",
    "print(train_len)\n",
    "\n",
    "# validation set 분리\n",
    "X_val = X_train[:train_len]\n",
    "y_val = y_train[:train_len]\n",
    "\n",
    "# validation set을 제외한 \n",
    "partial_X_train = X_train[train_len:]  \n",
    "partial_y_train = y_train[train_len:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa304fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c92522",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1ecf98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 3488      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,003,569\n",
      "Trainable params: 1,003,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = tf.keras.Sequential()\n",
    "rnn_model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "rnn_model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "rnn_model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "rnn_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e538f",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aa43e38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = tf.keras.Sequential()\n",
    "cnn_model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "cnn_model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "cnn_model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "cnn_model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be3290",
   "metadata": {},
   "source": [
    "## globalMaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20b356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,000,817\n",
      "Trainable params: 1,000,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxpooling_model = tf.keras.Sequential()\n",
    "maxpooling_model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "maxpooling_model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "maxpooling_model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "maxpooling_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "maxpooling_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a1467",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26635735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 일단 프로젝트부터 제출하고 나중에 작성하자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629af54",
   "metadata": {},
   "source": [
    "# 5) 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080f56a",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a6e527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 5s 8ms/step - loss: 0.4930 - accuracy: 0.7859 - val_loss: 0.3646 - val_accuracy: 0.8464\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3334 - accuracy: 0.8602 - val_loss: 0.3421 - val_accuracy: 0.8521\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2993 - accuracy: 0.8758 - val_loss: 0.3378 - val_accuracy: 0.8544\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2740 - accuracy: 0.8871 - val_loss: 0.3427 - val_accuracy: 0.8562\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2523 - accuracy: 0.8978 - val_loss: 0.3463 - val_accuracy: 0.8552\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2314 - accuracy: 0.9076 - val_loss: 0.3583 - val_accuracy: 0.8536\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 얼리 스탑핑 콜백 생성\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # 모니터할 지표 설정 (검증 손실)\n",
    "                               patience=3,         # 성능이 개선되지 않더라도 기다릴 epoch 수\n",
    "                               restore_best_weights=True)  # 최적의 가중치로 복원할지 여부\n",
    "\n",
    "rnn_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = rnn_model.fit(partial_X_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping],  # 얼리 스탑핑 콜백 추가\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce20ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3470 - accuracy: 0.8490\n",
      "[0.3470018208026886, 0.848953366279602]\n"
     ]
    }
   ],
   "source": [
    "results = rnn_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65013c69",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e974017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 3s 6ms/step - loss: 0.4696 - accuracy: 0.7694 - val_loss: 0.3466 - val_accuracy: 0.8483\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.3139 - accuracy: 0.8675 - val_loss: 0.3298 - val_accuracy: 0.8573\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2677 - accuracy: 0.8904 - val_loss: 0.3296 - val_accuracy: 0.8606\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2181 - accuracy: 0.9156 - val_loss: 0.3500 - val_accuracy: 0.8561\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.1619 - accuracy: 0.9412 - val_loss: 0.3909 - val_accuracy: 0.8512\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9628 - val_loss: 0.4535 - val_accuracy: 0.8481\n"
     ]
    }
   ],
   "source": [
    "# 얼리 스탑핑 콜백 생성\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # 모니터할 지표 설정 (검증 손실)\n",
    "                               patience=3,         # 성능이 개선되지 않더라도 기다릴 epoch 수\n",
    "                               restore_best_weights=True)  # 최적의 가중치로 복원할지 여부\n",
    "\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "cnn_history = cnn_model.fit(partial_X_train,\n",
    "                            partial_y_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=512,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            callbacks=[early_stopping],  # 얼리 스탑핑 콜백 추가\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24ab719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3437 - accuracy: 0.8545\n",
      "[0.3437303304672241, 0.8544866442680359]\n"
     ]
    }
   ],
   "source": [
    "results = cnn_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811796cb",
   "metadata": {},
   "source": [
    "## globalMaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e9f41b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.5034 - accuracy: 0.7996 - val_loss: 0.3598 - val_accuracy: 0.8416\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3287 - accuracy: 0.8604 - val_loss: 0.3372 - val_accuracy: 0.8515\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.8835 - val_loss: 0.3375 - val_accuracy: 0.8546\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.2485 - accuracy: 0.9011 - val_loss: 0.3455 - val_accuracy: 0.8547\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.2173 - accuracy: 0.9163 - val_loss: 0.3606 - val_accuracy: 0.8534\n"
     ]
    }
   ],
   "source": [
    "# 얼리 스탑핑 콜백 생성\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # 모니터할 지표 설정 (검증 손실)\n",
    "                               patience=3,         # 성능이 개선되지 않더라도 기다릴 epoch 수\n",
    "                               restore_best_weights=True)  # 최적의 가중치로 복원할지 여부\n",
    "\n",
    "maxpooling_model.compile(optimizer='adam',\n",
    "                         loss='binary_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = maxpooling_model.fit(partial_X_train,\n",
    "                               partial_y_train,\n",
    "                               epochs=epochs,\n",
    "                               batch_size=512,\n",
    "                               validation_data=(X_val, y_val),\n",
    "                               callbacks=[early_stopping],  # 얼리 스탑핑 콜백 추가\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99bdc4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.3476 - accuracy: 0.8480\n",
      "[0.3475850522518158, 0.8480378985404968]\n"
     ]
    }
   ],
   "source": [
    "results = maxpooling_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786e513",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e506fe3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 일단 프로젝트부터 제출하고 나중에 작성하자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaec435",
   "metadata": {},
   "source": [
    "# 6) Loss, Accuracy 그래프 시각화\n",
    "가장 성능이 좋은 cnn_model에 대해서만 진행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c35c307e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = cnn_history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0eed98",
   "metadata": {},
   "source": [
    "# 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77270f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = cnn_model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18313d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = cnn_model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c8ef635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02626232, -0.03950468,  0.00939648,  0.06164891, -0.03509895,\n",
       "       -0.06295256, -0.05085923,  0.01619131,  0.05957789,  0.0255749 ,\n",
       "        0.059303  , -0.00419919, -0.03934383, -0.06209003,  0.00353901,\n",
       "        0.0197657 , -0.05457802, -0.00507609, -0.03478932, -0.0124198 ,\n",
       "        0.02686845, -0.05159886, -0.05047621, -0.07202128, -0.02108471,\n",
       "       -0.04009546,  0.05650522,  0.02304755, -0.01785423, -0.04533763,\n",
       "        0.02638518, -0.02995886,  0.03013302, -0.09389636, -0.0130142 ,\n",
       "        0.01778838,  0.05514788, -0.0329087 , -0.03465988, -0.00101185,\n",
       "        0.08075269, -0.03256844, -0.0433308 ,  0.05483233,  0.05076853,\n",
       "        0.03054587,  0.05299909,  0.03554324,  0.07013498, -0.01134818,\n",
       "        0.05779673,  0.03696076, -0.06125243, -0.04968997,  0.01268024,\n",
       "        0.03215992,  0.0025589 , -0.02044596,  0.02396721, -0.00262887,\n",
       "        0.05712419,  0.049075  ,  0.02737638, -0.01594786, -0.03852091,\n",
       "       -0.06793676, -0.0262545 , -0.01933274,  0.06825554,  0.01522185,\n",
       "        0.0575267 , -0.00059046, -0.06876647,  0.02452989, -0.04103281,\n",
       "       -0.05646074,  0.01051653, -0.00175254,  0.08984661, -0.01841002,\n",
       "       -0.03261403,  0.00083031,  0.02003686, -0.01789127,  0.03498201,\n",
       "       -0.01592475,  0.06524295,  0.00331409, -0.00413889,  0.00189885,\n",
       "        0.03044199, -0.02965483, -0.04393386, -0.01585759, -0.07756291,\n",
       "       -0.03585282, -0.01152094, -0.04219056, -0.03824556, -0.03592246],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['영화']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d2fdcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('네요', 0.4436160624027252),\n",
       " ('하이틴', 0.44052302837371826),\n",
       " ('어요', 0.4321979582309723),\n",
       " ('B', 0.39571475982666016),\n",
       " ('데이', 0.3774283528327942),\n",
       " ('담겨', 0.37695813179016113),\n",
       " ('므로', 0.374747633934021),\n",
       " ('달까', 0.3739006519317627),\n",
       " ('요', 0.3696781396865845),\n",
       " ('이뻐서', 0.36833685636520386)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"영화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb84220c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = cnn_model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb9f9d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_path = '/aiffel/aiffel/sentiment_classification/data/word2vec_ko.model'\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_path)\n",
    "vector = word_vectors.wv['영화']\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f09c4f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('드라마', 0.8418774008750916),\n",
       " ('뮤지컬', 0.7775140404701233),\n",
       " ('코미디', 0.7489107251167297),\n",
       " ('다큐멘터리', 0.7401294708251953),\n",
       " ('헐리우드', 0.7397844195365906),\n",
       " ('애니메이션', 0.7170552015304565),\n",
       " ('독립영화', 0.7113528251647949),\n",
       " ('로맨틱', 0.7107657194137573),\n",
       " ('장편', 0.7101576924324036),\n",
       " ('극영화', 0.7045413255691528)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word_vectors.wv.similar_by_word(\"영화\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bba035",
   "metadata": {},
   "source": [
    "직접 학습한 embedding_layer와 비교했을 때 좀 더 비슷한 토큰이 더 많이 나옴. 직접 학습한 모델에서 데이터가 부족해서 발생하는 현상같음.<br>\n",
    "유사도도 보면 0.5가 넘지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eef2b7",
   "metadata": {},
   "source": [
    "# 8) 한국어 Word2Vec 임베딩 활용하여 성능 개선\n",
    "- word2vec_ko.model 활용\n",
    "- load() 형태로 모둘 불러오기. .wv 붙여서 활용.\n",
    "- [ ] 자체학습한 임베딩과 사전학습 임베딩 비교 분석\n",
    "- [ ] 네이버 영화리뷰 데이터 감성분석 정확도 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9adcd21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 16)            11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 100\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word_vectors.wv:\n",
    "        embedding_matrix[i] = word_vectors.wv[index_to_word[i]]\n",
    "\n",
    "cnn_model = tf.keras.Sequential()\n",
    "cnn_model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "cnn_model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "cnn_model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "cnn_model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a719b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 2s 6ms/step - loss: 0.5966 - accuracy: 0.6630 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.4604 - accuracy: 0.7848 - val_loss: 0.4377 - val_accuracy: 0.7997\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8219 - val_loss: 0.4023 - val_accuracy: 0.8212\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.3587 - accuracy: 0.8436 - val_loss: 0.3766 - val_accuracy: 0.8356\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.3319 - accuracy: 0.8573 - val_loss: 0.3685 - val_accuracy: 0.8391\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.3106 - accuracy: 0.8682 - val_loss: 0.3704 - val_accuracy: 0.8410\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2916 - accuracy: 0.8780 - val_loss: 0.3607 - val_accuracy: 0.8442\n",
      "Epoch 8/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2769 - accuracy: 0.8859 - val_loss: 0.3663 - val_accuracy: 0.8457\n",
      "Epoch 9/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2649 - accuracy: 0.8922 - val_loss: 0.3724 - val_accuracy: 0.8451\n",
      "Epoch 10/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2530 - accuracy: 0.8982 - val_loss: 0.3687 - val_accuracy: 0.8430\n"
     ]
    }
   ],
   "source": [
    "# 얼리 스탑핑 콜백 생성\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # 모니터할 지표 설정 (검증 손실)\n",
    "                               patience=3,         # 성능이 개선되지 않더라도 기다릴 epoch 수\n",
    "                               restore_best_weights=True)  # 최적의 가중치로 복원할지 여부\n",
    "\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "cnn_history = cnn_model.fit(partial_X_train,\n",
    "                            partial_y_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=512,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            callbacks=[early_stopping],  # 얼리 스탑핑 콜백 추가\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "119330b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3677 - accuracy: 0.8411\n",
      "[0.3677394986152649, 0.8410806059837341]\n"
     ]
    }
   ],
   "source": [
    "results = cnn_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e77980",
   "metadata": {},
   "source": [
    "직접 학습한 embedding_layer를 사용했을 때보다 정확도가 0.01 정도 작음. 기존 모델의 embedding이 naver 영화 리뷰 데이터의 특징을 더 잘 잡아냈을 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90abf4aa",
   "metadata": {},
   "source": [
    "## 모델 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cf4329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.regularizers import l2  # l2 임포트 추가\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential([\n",
    "            layers.Embedding(vocab_size, \n",
    "                             word_vector_dim, \n",
    "                             embeddings_initializer=Constant(embedding_matrix),\n",
    "                             input_length=maxlen, trainable=True),\n",
    "            layers.Conv1D(\n",
    "                filters=hp.Int('conv1_filters', min_value=16, max_value=128, step=16),\n",
    "                kernel_size=7,\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(hp.Choice('l2_conv1', values=[0.01, 0.001, 0.0001]))\n",
    "            ),\n",
    "            layers.MaxPooling1D(5),\n",
    "            layers.Dropout(hp.Float('dropout1', 0, 0.5, step=0.1)),\n",
    "            layers.Conv1D(\n",
    "                filters=hp.Int('conv2_filters', min_value=16, max_value=128, step=16),\n",
    "                kernel_size=7,\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(hp.Choice('l2_conv2', values=[0.01, 0.001, 0.0001]))\n",
    "            ),\n",
    "            layers.GlobalMaxPooling1D(),\n",
    "            layers.Dense(\n",
    "                units=hp.Int('dense_units', min_value=16, max_value=128, step=16),\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(hp.Choice('l2_dense', values=[0.01, 0.001, 0.0001]))\n",
    "            ),\n",
    "            layers.Dropout(hp.Float('dropout2', 0, 0.5, step=0.1)),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        optimizer = hp.Choice(name=\"optimizer\", values=[\"adam\"])\n",
    "        model.compile(optimizer = optimizer,\n",
    "                     loss = 'binary_crossentropy',\n",
    "                     metrics = ['accuracy'])\n",
    "        return model\n",
    "\n",
    "hypermodel = SimpleMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5086d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"mnist_kt_test\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d874bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 9\n",
      "conv1_filters (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "l2_conv1 (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "dropout1 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "conv2_filters (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "l2_conv2 (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "l2_dense (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "dropout2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c873a52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 55s]\n",
      "val_accuracy: 0.8563928008079529\n",
      "\n",
      "Best val_accuracy So Far: 0.8610445857048035\n",
      "Total elapsed time: 00h 10m 35s\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5),\n",
    "]\n",
    "tuner.search(\n",
    "    partial_X_train,\n",
    "    partial_y_train,\n",
    "    batch_size=512,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "540e47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 1\n",
    "best_hps = tuner.get_best_hyperparameters(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5e69838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(top_n)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98f2f4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_save_path = 'best_model.h5'\n",
    "best_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "972e6d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Epoch 1/20\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 0.2901 - accuracy: 0.9019 - val_loss: 0.3768 - val_accuracy: 0.8611\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 2s 7ms/step - loss: 0.2845 - accuracy: 0.9042 - val_loss: 0.3870 - val_accuracy: 0.8591\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 2s 7ms/step - loss: 0.2813 - accuracy: 0.9058 - val_loss: 0.3849 - val_accuracy: 0.8596\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 2s 7ms/step - loss: 0.2796 - accuracy: 0.9057 - val_loss: 0.3967 - val_accuracy: 0.8593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x796c6d3cf7c0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = 'best_model.h5'\n",
    "best_model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "best_model.fit(partial_X_train,\n",
    "               partial_y_train,\n",
    "               epochs=epochs,\n",
    "               batch_size=512,\n",
    "               validation_data=(X_val, y_val),\n",
    "               callbacks=[early_stopping],  # 얼리 스탑핑 콜백 추가\n",
    "               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3af82f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3862 - accuracy: 0.8577\n",
      "[0.38620850443840027, 0.857660174369812]\n"
     ]
    }
   ],
   "source": [
    "results = best_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1bd048",
   "metadata": {},
   "source": [
    "# 회고\n",
    "tuner.search를 저장하지 않은게 아쉬움. 생각보다 시간이 많이 들었음.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab6c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
